{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e7c3aad-f17c-4357-91a5-70c116740ac4",
   "metadata": {},
   "source": [
    "# Overfitting and Underfitting\n",
    "\n",
    "Models too complex for the data overfit:\n",
    "* they explain too well the data that they have seen\n",
    "* they do not generalize\n",
    "\n",
    "Models too simple for the data underfit:\n",
    "* they capture no noise\n",
    "* they are limited by their expressivity\n",
    "\n",
    "How to find the right trade-off?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b78d4f9-4eaa-4462-9b77-c321a2722934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Disable jedi autocompleter\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca2d33e-7535-43b2-b7a8-e21f1e6a808c",
   "metadata": {},
   "source": [
    "## The Framework and why do we need it\n",
    "\n",
    "In this section we intend to go into details into the cross-validation framework.  \n",
    "Before we dive in, let's linger on the reasons for always having training and testing sets. Letâ€™s first look at the limitation of using a dataset without keeping any samples out.\n",
    "\n",
    "To illustrate the different concepts, we will use the California housing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54839112-bb02-4d3b-9c29-041c3d27f7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "211eb3eb-044a-492c-bdb5-0c2f38b046dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing = fetch_california_housing(as_frame=True)\n",
    "type(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf6f0b9d-05c7-47fc-95b2-f86f1258291f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'feature_names', 'frame', 'target', 'target_names']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cae0a8f8-8dee-4ba9-8cb8-b1472e57a424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  \n",
       "0    -122.23  \n",
       "1    -122.22  \n",
       "2    -122.24  \n",
       "3    -122.25  \n",
       "4    -122.25  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = housing.data\n",
    "target = housing.target\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc55a196-6134-4603-843f-0f61c6b88b76",
   "metadata": {},
   "source": [
    "To simplify future visualtization, let's transform the prices from the 100 (k\\\\$) range to the thousand dollars (k\\\\$) range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1a5ebe0-61f8-4478-af66-a65e17e857b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    452.6\n",
       "1    358.5\n",
       "2    352.1\n",
       "3    341.3\n",
       "4    342.2\n",
       "Name: MedHouseVal, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target *= 100\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fb2030-3be8-487f-8714-9ad9c0e0526c",
   "metadata": {},
   "source": [
    "## Training Error vs. Testing Error\n",
    "\n",
    "To solve this regression task, we will use a decision tree regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2c4825a-6dd1-4429-b50c-6f8554c71e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(random_state=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "regressor = DecisionTreeRegressor(random_state=0)\n",
    "regressor.fit(data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65451d26-c12c-462f-a8df-fff492187c33",
   "metadata": {},
   "source": [
    "After training the regressor, we sould like to know it potential generalization performance once deployed in production. For this purpose, we use the <code style=\"background:yellow;color:black\">mean absolute error</code>, which gives us an error in the native unit, i.e. k\\\\$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a82a4b1e-16ba-4f0d-8028-e7b4629827ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On average, our regressor makes an error of 0.00 k$\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "target_predicted = regressor.predict(data)\n",
    "score = mean_absolute_error(target, target_predicted)\n",
    "print(f\"On average, our regressor makes an error of {score:.2f} k$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ee631e-b509-4c74-8315-c11a74331462",
   "metadata": {},
   "source": [
    "We get a perfect prediction with no errors. It is too optimistic and almost always revealing a methodological problem when doing machine learning.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Indeed, we trained and predicted on the same dataset. Since our decision tree was fully grown, every sample in the dataset is stored in a leaf node. Therefore, our decision tree fully memorized the dataset given during <em>fit</em> and therefore made no error when predicting.</div>\n",
    "\n",
    "This error computed above is called the <code style=\"background:yellow;color:black\">empirical error or training error</code>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fc649e-48a6-4157-aaf7-986fff67e383",
   "metadata": {},
   "source": [
    "We trained a predictive model to minimize the training error but our aim is to minimize the error on data that has not been seen during training.\n",
    "\n",
    "This error is also called the <code style=\"background:yellow;color:black\">generalization error or the \"true\" testing error</code>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb67a881-5513-4104-9792-05c09bfd5761",
   "metadata": {},
   "source": [
    "Thus the most basic evaluation involves:\n",
    "\n",
    "* splitting our dataset into two subsets: a training set and a testing set;\n",
    "* fitting the model on the training set;\n",
    "* estimating the training error on the trainin set;\n",
    "* estimating the testing error on the testing set.\n",
    "\n",
    "So let's split our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68204428-77ff-4e9b-974f-448627b125c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split                                                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95c7de7-cd2d-4e5d-8279-015aa4b69e61",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Side Note: </b>It is better to keep your imports in one cell, and the code in the next one, in order to use the helper keyboard shortcut [shift] + [tab], in case you don't know what input parameters are required.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7969eb50-ee19-449c-a4f6-923e63b10c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test, target_train, target_test = train_test_split(data, target, \n",
    "                                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efccdd37-b0ae-4212-91ac-decd59c6fc7b",
   "metadata": {},
   "source": [
    "Then, let's train our model using the `data_train` and `target_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1c7b9b4-88dc-43e0-bc23-6c536f1ad041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(random_state=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(data_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2870bd-edef-469d-880d-c31c8b396295",
   "metadata": {},
   "source": [
    "Finally, we estimate the different types of errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b6c90b3-a7d7-42c3-b83e-00bb247401f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error of our model is 0.00 k$\n"
     ]
    }
   ],
   "source": [
    "# Let's start with the training error\n",
    "target_predicted = regressor.predict(data_train)\n",
    "score = mean_absolute_error(target_train, target_predicted)\n",
    "print(f\"The training error of our model is {score:.2f} k$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedf653e-7eb0-444a-a58e-babe7524fe09",
   "metadata": {},
   "source": [
    "We observe the same phenomena as before: our model memorized the training set. However, we now compute the testing error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92d552f6-e189-42fb-aa38-fe3bcc2f62d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing error of our model is 47.28 k$\n"
     ]
    }
   ],
   "source": [
    "target_predicted = regressor.predict(data_test)\n",
    "score = mean_absolute_error(target_test, target_predicted)\n",
    "print(f\"The testing error of our model is {score:.2f} k$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd94606-20e0-4ed8-a8d6-537b3c914a28",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "This testing error is actually about what we would expect from our model if it was used in a production environment.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21455662-18c6-452e-9014-de1c74d8b5b5",
   "metadata": {},
   "source": [
    "## Stability of the Cross-Validation Estimates\n",
    "\n",
    "When doing a single train-test split we don't give any idication regarding the robustness of the evaluation of our predictive model: in particular, if the test set is small, this estimate of the testing error will be unstable and wouldn't reflect the \"true error rate\" we would have observed with the same model on an unlimited amount of test data.\n",
    "\n",
    "**Coss-Validation** allows estimating the robustness of apredictive model by repeating the splitting procedure. It will give several training and testing errors and thus some <code style=\"background:yellow;color:black\">estimate of the variability of the model generalization performance.</code>\n",
    "\n",
    "There are different cross-validation strategies, for now we are going to focus on one called \"shuffle-split\". At each iteration of this strategy we:\n",
    "\n",
    "  * randomly shuffle the order of the samples of a copy of the full dataset;\n",
    "  * split the shuffled dataset into a train and a test set;\n",
    "  * train a new model on the train set;\n",
    "  * evaluate the testing error on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d97498-5d1c-4149-b591-a52384c221c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
