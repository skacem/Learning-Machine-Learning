{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fe825b1-265b-4ea0-9b1e-01bcef04d87f",
   "metadata": {},
   "source": [
    "# Exercise M6.01\n",
    "\n",
    "The aim of this notebook is to investigate if we can tune the hyperparameters of a bagging regressor and evaluate the gain obtained.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8d1dd62-027c-45f8-ae52-d5f6177dc7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data, target = fetch_california_housing(as_frame=True, return_X_y=True)\n",
    "target *= 100\n",
    "data_train, data_test, target_train, target_test = train_test_split(data,\n",
    "                                                                   target,\n",
    "                                                                   random_state=0,\n",
    "                                                                   test_size=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f937c19-77cb-4e4a-a1b2-d351f2a293d5",
   "metadata": {},
   "source": [
    "Create a `BaggingRegressor` and provide a `DecisionTreeRegressor` to its parameter `base_estimator`. Train the regressor and evaluate its generalization performance on the testing set using the mean absolute error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1851bb3d-69b8-4f46-a6ed-0e462ee52c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2d6ad5f-c421-4d59-a2c4-bd1ac7c0dba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagged_trees = BaggingRegressor(\n",
    "        base_estimator=DecisionTreeRegressor(), n_jobs=2)\n",
    "bagged_trees.fit(data_train, target_train);\n",
    "target_predicted = bagged_trees.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57cf0763-1e2c-45cc-b83c-311d866c8996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic mean absolute error of the bagging regressor:\n",
      "36.15 k$\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "print(f\"Basic mean absolute error of the bagging regressor:\\n\"\n",
    "      f\"{mean_absolute_error(target_test, target_predicted):.2f} k$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b853bf81-f721-445c-9cd7-8d5992bb26ce",
   "metadata": {},
   "source": [
    "Now, create a `RandomizedSearchCV` instance using the previous model and tune the important parameters of the bagging regressor. Find the best parameters and check if you are able to find aset of parameters that improve the default regressor still using the mean absolute error as metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57d0ebf5-1dcc-4643-be2b-63899cae1045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_estimator__ccp_alpha': 0.0,\n",
       " 'base_estimator__criterion': 'squared_error',\n",
       " 'base_estimator__max_depth': None,\n",
       " 'base_estimator__max_features': None,\n",
       " 'base_estimator__max_leaf_nodes': None,\n",
       " 'base_estimator__min_impurity_decrease': 0.0,\n",
       " 'base_estimator__min_samples_leaf': 1,\n",
       " 'base_estimator__min_samples_split': 2,\n",
       " 'base_estimator__min_weight_fraction_leaf': 0.0,\n",
       " 'base_estimator__random_state': None,\n",
       " 'base_estimator__splitter': 'best',\n",
       " 'base_estimator': DecisionTreeRegressor(),\n",
       " 'bootstrap': True,\n",
       " 'bootstrap_features': False,\n",
       " 'max_features': 1.0,\n",
       " 'max_samples': 1.0,\n",
       " 'n_estimators': 10,\n",
       " 'n_jobs': 2,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagged_trees.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12575520-cc1c-4eee-8bd9-8e28cf3a2375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38ab1aa3-bef5-44f2-87a0-83a1de4908fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": randint(10, 50),\n",
    "    \"max_samples\": [0.5, 0.8, 1.0],\n",
    "    \"max_features\": [0.5, 0.8, 1.0],\n",
    "    \"base_estimator__max_depth\": randint(3, 10),\n",
    "}\n",
    "search = RandomizedSearchCV(\n",
    "    bagged_trees, param_grid, n_iter=30, scoring=\"neg_mean_absolute_error\"\n",
    ")\n",
    "_ = search.fit(data_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa1e4384-cf86-4ddc-8dad-7ca7ae40cb60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_samples</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_base_estimator__max_depth</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>9</td>\n",
       "      <td>38.306286</td>\n",
       "      <td>1.188887</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>47</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>9</td>\n",
       "      <td>38.666826</td>\n",
       "      <td>1.489754</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>9</td>\n",
       "      <td>39.760116</td>\n",
       "      <td>0.618540</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>40.739568</td>\n",
       "      <td>1.120723</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>33</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>40.815774</td>\n",
       "      <td>0.857368</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>8</td>\n",
       "      <td>41.309310</td>\n",
       "      <td>0.982196</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>41</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7</td>\n",
       "      <td>42.418271</td>\n",
       "      <td>1.132872</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>34</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>43.016294</td>\n",
       "      <td>1.130351</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>9</td>\n",
       "      <td>45.307578</td>\n",
       "      <td>1.644684</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8</td>\n",
       "      <td>45.827778</td>\n",
       "      <td>1.798991</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8</td>\n",
       "      <td>46.118480</td>\n",
       "      <td>1.863134</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>31</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8</td>\n",
       "      <td>46.170571</td>\n",
       "      <td>0.955637</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7</td>\n",
       "      <td>47.311157</td>\n",
       "      <td>0.818832</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7</td>\n",
       "      <td>47.482843</td>\n",
       "      <td>1.898426</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5</td>\n",
       "      <td>48.539486</td>\n",
       "      <td>1.106120</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6</td>\n",
       "      <td>50.364284</td>\n",
       "      <td>2.024090</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>16</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>51.370636</td>\n",
       "      <td>1.108428</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>22</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>51.407742</td>\n",
       "      <td>1.064777</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>46</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>51.570282</td>\n",
       "      <td>1.121857</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>51.818002</td>\n",
       "      <td>1.137728</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>51.844574</td>\n",
       "      <td>1.105782</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>51.873275</td>\n",
       "      <td>0.921447</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4</td>\n",
       "      <td>52.321434</td>\n",
       "      <td>0.961070</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>46</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4</td>\n",
       "      <td>52.349789</td>\n",
       "      <td>1.324663</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4</td>\n",
       "      <td>52.494894</td>\n",
       "      <td>1.678867</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>31</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "      <td>56.141660</td>\n",
       "      <td>1.065514</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>33</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>56.725778</td>\n",
       "      <td>0.988942</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>56.796561</td>\n",
       "      <td>1.184244</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3</td>\n",
       "      <td>56.958543</td>\n",
       "      <td>0.826751</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3</td>\n",
       "      <td>57.477058</td>\n",
       "      <td>0.887798</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_n_estimators param_max_samples param_max_features  \\\n",
       "18                 28               1.0                0.8   \n",
       "26                 47               0.8                0.8   \n",
       "9                  11               0.8                0.8   \n",
       "27                 28               0.8                1.0   \n",
       "12                 33               0.5                1.0   \n",
       "29                 15               0.5                0.8   \n",
       "22                 41               0.5                0.8   \n",
       "8                  34               0.8                1.0   \n",
       "6                  41               1.0                0.5   \n",
       "3                  47               1.0                0.5   \n",
       "7                  38               0.8                0.5   \n",
       "16                 31               0.5                0.5   \n",
       "0                  43               0.5                0.5   \n",
       "1                  23               1.0                0.5   \n",
       "4                  18               0.8                0.8   \n",
       "13                 14               1.0                0.5   \n",
       "25                 16               0.5                1.0   \n",
       "19                 22               0.5                1.0   \n",
       "14                 46               0.8                1.0   \n",
       "20                 40               1.0                1.0   \n",
       "28                 24               1.0                1.0   \n",
       "11                 19               1.0                1.0   \n",
       "10                 39               1.0                0.8   \n",
       "17                 46               0.8                0.8   \n",
       "5                  28               1.0                0.8   \n",
       "15                 31               0.5                0.5   \n",
       "24                 33               0.8                1.0   \n",
       "21                 18               1.0                1.0   \n",
       "2                  28               0.5                0.8   \n",
       "23                 49               1.0                0.8   \n",
       "\n",
       "   param_base_estimator__max_depth  mean_test_score  std_test_score  \\\n",
       "18                               9        38.306286        1.188887   \n",
       "26                               9        38.666826        1.489754   \n",
       "9                                9        39.760116        0.618540   \n",
       "27                               8        40.739568        1.120723   \n",
       "12                               8        40.815774        0.857368   \n",
       "29                               8        41.309310        0.982196   \n",
       "22                               7        42.418271        1.132872   \n",
       "8                                7        43.016294        1.130351   \n",
       "6                                9        45.307578        1.644684   \n",
       "3                                8        45.827778        1.798991   \n",
       "7                                8        46.118480        1.863134   \n",
       "16                               8        46.170571        0.955637   \n",
       "0                                7        47.311157        0.818832   \n",
       "1                                7        47.482843        1.898426   \n",
       "4                                5        48.539486        1.106120   \n",
       "13                               6        50.364284        2.024090   \n",
       "25                               4        51.370636        1.108428   \n",
       "19                               4        51.407742        1.064777   \n",
       "14                               4        51.570282        1.121857   \n",
       "20                               4        51.818002        1.137728   \n",
       "28                               4        51.844574        1.105782   \n",
       "11                               4        51.873275        0.921447   \n",
       "10                               4        52.321434        0.961070   \n",
       "17                               4        52.349789        1.324663   \n",
       "5                                4        52.494894        1.678867   \n",
       "15                               4        56.141660        1.065514   \n",
       "24                               3        56.725778        0.988942   \n",
       "21                               3        56.796561        1.184244   \n",
       "2                                3        56.958543        0.826751   \n",
       "23                               3        57.477058        0.887798   \n",
       "\n",
       "    rank_test_score  \n",
       "18                1  \n",
       "26                2  \n",
       "9                 3  \n",
       "27                4  \n",
       "12                5  \n",
       "29                6  \n",
       "22                7  \n",
       "8                 8  \n",
       "6                 9  \n",
       "3                10  \n",
       "7                11  \n",
       "16               12  \n",
       "0                13  \n",
       "1                14  \n",
       "4                15  \n",
       "13               16  \n",
       "25               17  \n",
       "19               18  \n",
       "14               19  \n",
       "20               20  \n",
       "28               21  \n",
       "11               22  \n",
       "10               23  \n",
       "17               24  \n",
       "5                25  \n",
       "15               26  \n",
       "24               27  \n",
       "21               28  \n",
       "2                29  \n",
       "23               30  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columns = [f\"param_{name}\" for name in param_grid.keys()]\n",
    "columns += [\"mean_test_score\", \"std_test_score\", \"rank_test_score\"]\n",
    "cv_results = pd.DataFrame(search.cv_results_)\n",
    "cv_results = cv_results[columns].sort_values(by=\"rank_test_score\")\n",
    "cv_results[\"mean_test_score\"] = -cv_results[\"mean_test_score\"]\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82911718-002b-44be-9033-670e0778fada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error after tuning of the bagging regressor:\n",
      "38.95 k$\n"
     ]
    }
   ],
   "source": [
    "target_predicted = search.predict(data_test)\n",
    "print(f\"Mean absolute error after tuning of the bagging regressor:\\n\"\n",
    "      f\"{mean_absolute_error(target_test, target_predicted):.2f} k$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f0e84d-16a0-4ff9-b54c-289ddd7ab111",
   "metadata": {},
   "source": [
    "We see that the predictor provided by the bagging regressor does not need much hyperparameter tuning compared to a single decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ea6fbe-06ba-460f-b2fd-8ca1696da7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
