{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c858c46-b4bf-4d59-9918-65f14ddd01ac",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc86bd1a-98cb-4000-bb2c-5dd50e9809f1",
   "metadata": {},
   "source": [
    "In the previous section, we did not discuss the parameters of random forest and gradient-boosting. However, there are a couple of things to keep in mind when  setting these.  \n",
    "\n",
    "This notebook gives crucial information regarding how to set the hyperparameters of both random forest and gradient boosting decision tree models.\n",
    "\n",
    "## Random Forest\n",
    "\n",
    "The main parameter to tune for random forest is the `n_estimators` parameters. In general, the more trees in the forest, the better the generalization performance will be. However, it will slow down the fitting and prediction time. The goal is to balance computing time and generalization performance when setting the number of estimators when putting such learner in production.  \n",
    "\n",
    "The `max_depth` parameter could also be tuned. Sometimes, there is no need to have fully grown trees. However, <code style=\"background:yellow; color:black\">be aware that with random forest, trees are generally deep since we are seeking to overfit the learners on the bootstrap samples because this will be mitigated by combining them.</code>  \n",
    "Assembling underfitted trees (i.e. shallow trees) might also lead to an underfitted forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "893e4a8b-3cbe-4d24-a9cf-67dbff5172b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f64f73a7-ec97-4968-baa5-3c090161e01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = fetch_california_housing(return_X_y=True, as_frame=True)\n",
    "target *= 100\n",
    "data_train, data_test, target_train, target_test = train_test_split(data, target,\n",
    "                                                                   random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98266f62-e57c-4e5a-923b-bfded8c9c5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac373dcb-da3c-4688-b439-3e7deef5aa07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30</td>\n",
       "      <td>None</td>\n",
       "      <td>34.602536</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>34.882662</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>36.103924</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>48.545337</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>48.681638</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>48.860571</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>57.061607</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>57.132398</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>57.140272</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_n_estimators param_max_depth  mean_test_score  rank_test_score\n",
       "8                 30            None        34.602536                1\n",
       "7                 20            None        34.882662                2\n",
       "6                 10            None        36.103924                3\n",
       "4                 20               5        48.545337                4\n",
       "5                 30               5        48.681638                5\n",
       "3                 10               5        48.860571                6\n",
       "2                 30               3        57.061607                7\n",
       "1                 20               3        57.132398                8\n",
       "0                 10               3        57.140272                9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [10, 20, 30],\n",
    "    \"max_depth\": [3, 5, None],\n",
    "}\n",
    "grid_search = GridSearchCV(RandomForestRegressor(n_jobs=2),\n",
    "                          param_grid=param_grid,\n",
    "                          scoring=\"neg_mean_absolute_error\", n_jobs=2)\n",
    "grid_search.fit(data_train, target_train)\n",
    "\n",
    "columns = [f\"param_{name}\" for name in param_grid.keys()]\n",
    "columns += [\"mean_test_score\", \"rank_test_score\"]\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results[\"mean_test_score\"] = -cv_results[\"mean_test_score\"]\n",
    "cv_results[columns].sort_values(by=\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9124aaf5-c816-4b11-bd9e-ecf92bde17cd",
   "metadata": {},
   "source": [
    "We can observe that in our grid-search, the largest `max_depth` together with the largest `n_estimators` led to the best generalization performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721a5582-8470-4ea3-9ac2-740694c57c2f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Caution:</b> For the sake of clarity, no cross validation is used to estimate the testing error. We are only showing the effect of the parameters on the validation set of what should be the inner cross-validation.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385cfb6f-76a9-454f-a4f4-84290ef67642",
   "metadata": {},
   "source": [
    "## Gradient-boosting decision trees\n",
    "\n",
    "For gradient-boosting, parameters are coupled, so we cannot set the parameters one after the other anymore.  \n",
    "The important parameters are `n_estimators, max_depth`, and `learnin_rate`.\n",
    "\n",
    "Let's first discuss the `max_depth` parameter. We saw in the section on gradient boosting that the algorithm fits the error of the previous tree in the ensemble. Thus, fitting fully grown trees will be detrimental. Indeed, the frist tree of the ensemble would perfectly fit (overfit) the data and thus no subsequent tree would be required, since there would be no residuals. Therefore, the tree used in gradient-boosting should have a low depth, typically between 3 to 8 levels. Having very weak learners at each step will help reducing overfitting. \n",
    "\n",
    "With this consideration in mind, the deeper the trees, the faster the residuals will be corrrected and less learners are required. Therefore, `n_estimators` should be increased if `max_depth` is lower.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebb5e46-de3f-443b-a8aa-4859fa6e171e",
   "metadata": {},
   "source": [
    "Finally, we have overlooked the impact of the `learning_rate` parameter until now. When fitting the residuals, we would like the tree to try to correct all possible errors or only a fraction of them. The learning-rate allows you to control this behaviour. A small learning-rate value would only correct the residuals of very few samples. If a large learning-rate is set (e.g., 1), we would fit the residuals of all samples. So, with a very low learning-rate, we will need more estimators to correct the overall error. However, a too large learning-rate tends to obtain an overfitted ensemble, similar to having a too large tree depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c69ba74d-f58e-433c-9ee6-f73468168b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>35.659691</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>36.736890</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>37.437973</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>39.147928</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>39.274005</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>39.379441</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>39.890142</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>40.602042</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>41.589715</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>45.586703</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>45.756084</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>45.906537</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>47.237465</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>47.390248</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>30</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>47.550392</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>51.918522</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>56.355461</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>62.270268</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_n_estimators param_max_depth param_learning_rate  mean_test_score  \\\n",
       "5                  50               5                 0.1        35.659691   \n",
       "11                 50               3                   1        36.736890   \n",
       "10                 30               3                   1        37.437973   \n",
       "13                 30               5                   1        39.147928   \n",
       "4                  30               5                 0.1        39.274005   \n",
       "12                 10               5                   1        39.379441   \n",
       "14                 50               5                   1        39.890142   \n",
       "2                  50               3                 0.1        40.602042   \n",
       "9                  10               3                   1        41.589715   \n",
       "7                  30            None                 0.1        45.586703   \n",
       "1                  30               3                 0.1        45.756084   \n",
       "8                  50            None                 0.1        45.906537   \n",
       "17                 50            None                   1        47.237465   \n",
       "15                 10            None                   1        47.390248   \n",
       "16                 30            None                   1        47.550392   \n",
       "6                  10            None                 0.1        51.918522   \n",
       "3                  10               5                 0.1        56.355461   \n",
       "0                  10               3                 0.1        62.270268   \n",
       "\n",
       "    rank_test_score  \n",
       "5                 1  \n",
       "11                2  \n",
       "10                3  \n",
       "13                4  \n",
       "4                 5  \n",
       "12                6  \n",
       "14                7  \n",
       "2                 8  \n",
       "9                 9  \n",
       "7                10  \n",
       "1                11  \n",
       "8                12  \n",
       "17               13  \n",
       "15               14  \n",
       "16               15  \n",
       "6                16  \n",
       "3                17  \n",
       "0                18  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [10, 30, 50],\n",
    "    \"max_depth\": [3, 5, None],\n",
    "    \"learning_rate\": [0.1, 1],\n",
    "}\n",
    "grid_search = GridSearchCV(\n",
    "    GradientBoostingRegressor(), param_grid=param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\", n_jobs=2\n",
    ")\n",
    "grid_search.fit(data_train, target_train)\n",
    "\n",
    "columns = [f\"param_{name}\" for name in param_grid.keys()]\n",
    "columns += [\"mean_test_score\", \"rank_test_score\"]\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results[\"mean_test_score\"] = -cv_results[\"mean_test_score\"]\n",
    "cv_results[columns].sort_values(by=\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73a638b-9cba-4260-b0e3-0fcc8e699a46",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Caution:</b> Here, we tune the `n_estimators` but be aware that using early-stopping as in the previous exercise will be better.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3468ece-0a06-4fb3-9376-8cd6241519b9",
   "metadata": {},
   "source": [
    "## Main take-away\n",
    "\n",
    "So in this module, we discussed ensemble learners which are a type of learner that combines simpler learners together. We saw two strategies:\n",
    "\n",
    "* one based on bootstrap samples allowing learners to be fit in a parallel manner;\n",
    "* the other called boosting which fit learners sequentially.\n",
    "\n",
    "From these two families, we mainly focused on giving intuitions regarding the internal machinery of the random forest and gradient boosting models which are state-of-the-art methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ac3d44-69e3-451b-878c-571c599b44d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
